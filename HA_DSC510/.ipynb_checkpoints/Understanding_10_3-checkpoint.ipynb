{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Networked Programs II\n",
    "\n",
    "## Retrieving web pages with urllib\n",
    "\n",
    "In 9.2 Interest, I used the manual way to send and receive data over HTTP using socket module. The codes was not intuitive due to HTTP protocol and parsing data needed extra steps to clean up the data. There is a standard library named urllib makes it easy to retrieve data from the web. Since urllib handles a web page like a file, it will take care of HTTP protocol and cleansing up header details. The code using urllib becomes much simpler and easier to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'But soft what light through yonder window breaks\\n'\n",
      "b'It is the east and Juliet is the sun\\n'\n",
      "b'Arise fair sun and kill the envious moon\\n'\n",
      "b'Who is already sick and pale with grief\\n'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as request\n",
    "\n",
    "res = request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in res:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use read() method to retrieve all lines in one string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'But soft what light through yonder window breaks\\nIt is the east and Juliet is the sun\\nArise fair sun and kill the envious moon\\nWho is already sick and pale with grief\\n'\n"
     ]
    }
   ],
   "source": [
    "res = request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "print(res.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use readline() method to read one line by line. Every time we execute readline(), the program will return the next line. Once it returns all lines, then it will return an empty string thereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'But soft what light through yonder window breaks\\n'\n",
      "b'It is the east and Juliet is the sun\\n'\n",
      "b'Arise fair sun and kill the envious moon\\n'\n",
      "b'Who is already sick and pale with grief\\n'\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "res = request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "print(res.readline())\n",
    "print(res.readline())\n",
    "print(res.readline())\n",
    "print(res.readline())\n",
    "print(res.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use readlines() method to retrieve all lines in one `list` data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'But soft what light through yonder window breaks\\n', b'It is the east and Juliet is the sun\\n', b'Arise fair sun and kill the envious moon\\n', b'Who is already sick and pale with grief\\n']\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as request\n",
    "res = request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "print(res.readlines())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to parse only strings, we can use decode() method to parse only string. strip() method is used to remove extra lines between strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as request\n",
    "res = request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in res:\n",
    "    print(line.decode().strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading binary files using urllib\n",
    "\n",
    "Similarly, urllib can be used to retrieve a JPG file as well as other image and video files. We can open the URL, retrieve data using read() method, and write to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = request.urlopen('http://data.pr4e.org/cover3.jpg')\n",
    "image = res.read()\n",
    "file = open('cover3.jpg', 'wb')\n",
    "file.write(image)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "Basically, web scraper would do following tasks:\n",
    "\n",
    "- Retrieving HTML data from a domain name\n",
    "- Parsing that data for target information\n",
    "- Storing the target information\n",
    "- Moving to another web page to repeat the process \n",
    "\n",
    "Instead of retrieving files, we can download the data from the web page as HTML format\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"<!DOCTYPE html>\\n<html lang='en'>\\n    <head>\\n      \"\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "web_link = 'https://openweathermap.org/'\n",
    "html = urlopen(web_link)\n",
    "print(html.read(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to parse data in html tags, BeautifulSoup module can be used. The beautifulsoup4 library provide useful tools to parse data from html documents. For example, we can parse a tag from a beautifulsoup object as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<form action=\"/find\" class=\"pull-right hidden\" id=\"nav-search-form\" method=\"get\" role=\"search\">\n",
      "<div class=\"input-group\">\n",
      "<input class=\"form-control\" id=\"q\" name=\"q\" placeholder=\"Search\" type=\"text\"/>\n",
      "<span class=\"input-group-btn\">\n",
      "<button class=\"btn btn-default\" type=\"submit\"><i class=\"fa fa-search\"></i></button>\n",
      "</span>\n",
      "</div>\n",
      "</form>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "web_link = 'https://openweathermap.org/'\n",
    "html = urlopen(web_link)\n",
    "bsObj = BeautifulSoup(html.read())\n",
    "print(bsObj.div.form)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "Severance. C. R. (2009). Python for Everybody. http://do1.dr-chuck.com/pythonlearn/EN_us/pythonlearn.pdf \n",
    "Mitchell, Ryan (2015). Web Scraping with Python. Sebastopol, CA: Oâ€™Reilly Media, Inc.  \n",
    "Severance. C. R. (2009). Python for Everybody. http://do1.dr-chuck.com/pythonlearn/EN_us/pythonlearn.pdf  \n",
    "https://www.w3schools.com/python/default.asp  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
